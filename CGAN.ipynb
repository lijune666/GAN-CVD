{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntmBwfxB1o51"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.nn.init as init\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpW6oJ1b1sly"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3HvVwlWP1tt8"
      },
      "outputs": [],
      "source": [
        "df_knn = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/df_knn.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "piO5xkvh1vvY"
      },
      "outputs": [],
      "source": [
        "# split feature and label\n",
        "X = df_knn.drop('CVD0010', axis=1)\n",
        "y = df_knn['CVD0010']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5HrmhlK1vxf"
      },
      "outputs": [],
      "source": [
        "# normalize X_train, X_test\n",
        "scaler = StandardScaler()\n",
        "X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2D1z8PW1vz3"
      },
      "outputs": [],
      "source": [
        "# split train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8QKqIWI1v1w"
      },
      "outputs": [],
      "source": [
        "# hyperparameter\n",
        "n_epochs = 3500\n",
        "batch_size = 6666\n",
        "latent_dim = X_train.shape[1]\n",
        "condition_dim = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_DqVq-ESoSez"
      },
      "outputs": [],
      "source": [
        "# GAN model\n",
        "# generator_block\n",
        "def get_generator_block(input_dim, output_dim):\n",
        "    return nn.Sequential(\n",
        "        nn.Linear(input_dim, output_dim),\n",
        "        nn.BatchNorm1d(output_dim),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "    )\n",
        "# generator\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, z_dim=100, data_dim=latent_dim, c_dim=condition_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.gen = nn.Sequential(\n",
        "            get_generator_block(z_dim+c_dim, 128),\n",
        "            get_generator_block(128, 256),\n",
        "            get_generator_block(256, 512),\n",
        "            get_generator_block(512, 1024),\n",
        "            get_generator_block(1024, 2048),\n",
        "            nn.Linear(2048, data_dim),\n",
        "        )\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                init.kaiming_uniform_(m.weight.data, nonlinearity='leaky_relu')\n",
        "                if m.bias is not None:\n",
        "                    init.zeros_(m.bias.data)\n",
        "\n",
        "    def forward(self, noise, condition):\n",
        "        # Concatenate noise and condition\n",
        "        input_data = torch.cat([noise, condition], dim=1)\n",
        "        return self.gen(input_data)\n",
        "\n",
        "# discriminator_block\n",
        "def get_discriminator_block(input_dim, output_dim):\n",
        "    return nn.Sequential(\n",
        "        nn.Linear(input_dim, output_dim),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "        nn.Dropout(0.5)\n",
        "    )\n",
        "# 2.discriminator\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, data_dim=latent_dim, c_dim=condition_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.disc = nn.Sequential(\n",
        "            get_discriminator_block(data_dim+c_dim, 1024),\n",
        "            get_discriminator_block(1024, 512),\n",
        "            get_discriminator_block(512, 256),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "    def forward(self, data, condition):\n",
        "        # Concatenate data and condition\n",
        "        input_data = torch.cat([data, condition], dim=1)\n",
        "        return self.disc(input_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcvROb5111J0"
      },
      "outputs": [],
      "source": [
        "# Loss function\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Initialize generator and discriminator\n",
        "generator = Generator()\n",
        "discriminator = Discriminator()\n",
        "\n",
        "# Optimizers\n",
        "g_optimizer = torch.optim.Adam(generator.parameters(), lr=0.00001, betas=(0.5, 0.999))\n",
        "d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=0.00001, betas=(0.5, 0.999))\n",
        "\n",
        "# dataloader\n",
        "my_dataset = TensorDataset(torch.Tensor(X_train.values), torch.Tensor(y_train.values))\n",
        "dataloader = DataLoader(my_dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twSCoRtO12M7"
      },
      "outputs": [],
      "source": [
        "# original gan Train\n",
        "gen_losses = []\n",
        "disc_losses = []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    for index, (real_data_features, real_data_labels) in enumerate(dataloader):\n",
        "        real_data_features = real_data_features.float()\n",
        "        real_data_labels = real_data_labels.float().unsqueeze(-1)\n",
        "\n",
        "        # Adversarial ground truths\n",
        "        real_labels = torch.ones(real_data_labels.size(0), 1, requires_grad=False)\n",
        "        fake_labels = torch.zeros(real_data_labels.size(0), 1, requires_grad=False)\n",
        "\n",
        "        # -----------------\n",
        "        #  Train Generator (twice)\n",
        "        # -----------------\n",
        "\n",
        "        for _ in range(2):\n",
        "            g_optimizer.zero_grad()\n",
        "\n",
        "            # Sample noise as generator input\n",
        "            z = torch.randn(real_data_features.size(0), 100)\n",
        "            z_label = torch.tensor(torch.randint(0, 2, (real_data_labels.size(0), 1)))\n",
        "\n",
        "            # Generate a batch of datas\n",
        "            gen_datas = generator(z, z_label)\n",
        "\n",
        "            # Loss measures generator's ability to fool the discriminator\n",
        "            g_loss = criterion(discriminator(gen_datas, z_label), real_labels)\n",
        "\n",
        "            g_loss.backward()\n",
        "            g_optimizer.step()\n",
        "\n",
        "        # ---------------------\n",
        "        #  Train Discriminator\n",
        "        # ---------------------\n",
        "\n",
        "        d_optimizer.zero_grad()\n",
        "\n",
        "        # Measure discriminator's ability to classify real from generated samples\n",
        "        real_loss = criterion(discriminator(real_data_features, real_data_labels), real_labels)\n",
        "\n",
        "        # Generate a batch of datas\n",
        "        z = torch.randn(real_data_features.size(0), 100)\n",
        "        z_label = torch.tensor(torch.randint(0, 2, (real_data_labels.size(0), 1)))\n",
        "        gen_datas = generator(z, z_label).detach()\n",
        "\n",
        "        fake_loss = criterion(discriminator(gen_datas, z_label), fake_labels)\n",
        "        d_loss = (real_loss + fake_loss) / 2\n",
        "\n",
        "        d_loss.backward()\n",
        "        d_optimizer.step()\n",
        "\n",
        "        gen_losses.append(g_loss.item())\n",
        "        disc_losses.append(d_loss.item())\n",
        "\n",
        "        print(\n",
        "            \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
        "            % (epoch, n_epochs, index, len(dataloader), d_loss.item(), g_loss.item())\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3CNFLl5r12O7"
      },
      "outputs": [],
      "source": [
        "# Convert lists to NumPy arrays\n",
        "gen_losses = np.array(gen_losses)\n",
        "disc_losses = np.array(disc_losses)\n",
        "\n",
        "# Plot loss curves\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.plot(range(len(gen_losses)), gen_losses, label='Generator loss')\n",
        "plt.plot(range(len(disc_losses)), disc_losses, label='Discriminator loss')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eAf540-yLEAF"
      },
      "outputs": [],
      "source": [
        "indices = (y_train == 1)\n",
        "X_real = X_train[indices]\n",
        "y_real = y_train[indices]\n",
        "\n",
        "# count the frequency of each value in y_train.\n",
        "value_counts = y_train.value_counts()\n",
        "# calculate how much fewer the number of minority classes is than that of majority classes.\n",
        "diff = value_counts[0] - value_counts[1]\n",
        "\n",
        "# generate data\n",
        "z = torch.randn(diff, 100)\n",
        "z_label = torch.tensor(torch.randint(0, 2, (diff, 1)))\n",
        "generated_data = generator(z, z_label)\n",
        "generated_data_df = pd.DataFrame(generated_data.detach().numpy(), columns=X_train.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Co4-POaFEKV"
      },
      "outputs": [],
      "source": [
        "# t-SNE\n",
        "# original data (label==1)\n",
        "tsne_real = X_real # num == 76\n",
        "\n",
        "# smote data (label==1)\n",
        "tsne_real_gan = generated_data_df # num == 392\n",
        "\n",
        "# TSNE\n",
        "combined_data = pd.concat([tsne_real_gan, tsne_real], axis=0)\n",
        "labels = np.array([0] * len(tsne_real_gan) + [1] * len(tsne_real))\n",
        "tsne = TSNE(n_components=2, random_state=42)\n",
        "tsne_data = tsne.fit_transform(combined_data)\n",
        "\n",
        "# show\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(tsne_data[labels == 0, 0], tsne_data[labels == 0, 1], c='b', label='CGANan data')\n",
        "plt.scatter(tsne_data[labels == 1, 0], tsne_data[labels == 1, 1], c='r', label='Real data')\n",
        "plt.legend()\n",
        "plt.xlabel('Dimension 1')\n",
        "plt.ylabel('Dimension 2')\n",
        "plt.title('TSNE comparing real data with GAN generated data')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2i6zao_FZqg"
      },
      "outputs": [],
      "source": [
        "# PCA\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# merge two datas\n",
        "merged_data = np.concatenate((X_real, generated_data_df), axis=0)\n",
        "\n",
        "# PCA\n",
        "pca = PCA(n_components=2)  # dim==2\n",
        "reduced_data = pca.fit_transform(merged_data)\n",
        "\n",
        "# show\n",
        "plt.scatter(reduced_data[X_real.shape[0]:, 0], reduced_data[X_real.shape[0]:, 1], label='CGAN data')\n",
        "plt.scatter(reduced_data[:X_real.shape[0], 0], reduced_data[:X_real.shape[0], 1], label='Real data')\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSTTKL53lUFI"
      },
      "outputs": [],
      "source": [
        "value_counts = y_train.value_counts()\n",
        "diff = value_counts[0] - value_counts[1]\n",
        "\n",
        "# generate data\n",
        "z = torch.randn(diff, 100)\n",
        "z_label = torch.tensor(torch.randint(0, 2, (diff, 1)))\n",
        "generated_data = generator(z, z_label)\n",
        "generated_data_df = pd.DataFrame(generated_data.detach().numpy(), columns=X_train.columns)\n",
        "\n",
        "X_train_cgan = pd.concat([X_train, generated_data_df], axis=0)\n",
        "\n",
        "ones = pd.Series([1.0] * diff)\n",
        "\n",
        "y_train_cgan = y_train.append(ones, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nV1SXHvlipf"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import shuffle\n",
        "# shuffle\n",
        "X_train_cgan, y_train_cgan = shuffle(X_train_cgan, y_train_cgan)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2lUznurZic5"
      },
      "outputs": [],
      "source": [
        "#SVM\n",
        "import torch\n",
        "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve, average_precision_score, accuracy_score\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "def train_and_evaluate_svm(X_train, y_train, X_test, y_test):\n",
        "    X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
        "    y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
        "\n",
        "    # SVM\n",
        "    svm_classifier = SVC(probability=True)\n",
        "\n",
        "    # train\n",
        "    svm_classifier.fit(X_train_tensor.numpy(), y_train_tensor.numpy())\n",
        "\n",
        "    X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
        "    y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n",
        "\n",
        "    # test\n",
        "    y_scores = svm_classifier.predict_proba(X_test_tensor.numpy())[:, 1]\n",
        "    y_pred = svm_classifier.predict(X_test_tensor.numpy())\n",
        "\n",
        "    # FPR and TPR for ROC curve\n",
        "    fpr, tpr, thresholds = roc_curve(y_test_tensor.numpy(), y_scores)\n",
        "\n",
        "    # AUC\n",
        "    auc = roc_auc_score(y_test_tensor.numpy(), y_scores)\n",
        "\n",
        "    return auc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXyuixjkZk6g"
      },
      "outputs": [],
      "source": [
        "# original data\n",
        "roc_results = []\n",
        "\n",
        "# Repeat the training and evaluation process 30 times.\n",
        "num_repeats = 30\n",
        "for _ in range(num_repeats):\n",
        "    auc = train_and_evaluate_svm(X_train, y_train, X_test, y_test)\n",
        "    roc_results.append(auc)  # Store the AUC value in the tuple\n",
        "\n",
        "# Calculate the average value of evaluation indicators\n",
        "mean_auc = np.mean([result for result in roc_results])  # Retrieve the AUC value from the tuple\n",
        "\n",
        "print(\"Mean AUC:\", mean_auc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40JEPtAv7dWb"
      },
      "outputs": [],
      "source": [
        "# gan data\n",
        "roc_results_cgan = []\n",
        "\n",
        "# Repeat the training and evaluation process 30 times.\n",
        "num_repeats = 30\n",
        "for _ in range(num_repeats):\n",
        "    auc = train_and_evaluate_svm(X_train_cgan, y_train_cgan, X_test, y_test)\n",
        "    roc_results_cgan.append(auc)  # Store the AUC value in the tuple\n",
        "\n",
        "# Calculate the average value of evaluation indicators\n",
        "mean_auc_cgan = np.mean([result for result in roc_results_cgan])  # Retrieve the AUC value from the tuple\n",
        "\n",
        "print(\"CGAN Mean AUC:\", mean_auc_cgan)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}