{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "657c3502",
      "metadata": {
        "id": "657c3502"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.nn.init as init\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "pm-rFyoxBw7o"
      },
      "id": "pm-rFyoxBw7o",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e897dfdf",
      "metadata": {
        "id": "e897dfdf"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "485c78d2",
      "metadata": {
        "id": "485c78d2"
      },
      "outputs": [],
      "source": [
        "df_knn = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/df_knn.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87b6ce1e",
      "metadata": {
        "id": "87b6ce1e"
      },
      "outputs": [],
      "source": [
        "# split feature and label\n",
        "X = df_knn.drop('CVD0010', axis=1)\n",
        "y = df_knn['CVD0010']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16a4a838",
      "metadata": {
        "id": "16a4a838"
      },
      "outputs": [],
      "source": [
        "# normalize X_train, X_test\n",
        "scaler = StandardScaler()\n",
        "X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac8aaf38",
      "metadata": {
        "id": "ac8aaf38"
      },
      "outputs": [],
      "source": [
        "# split train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97815d80",
      "metadata": {
        "id": "97815d80"
      },
      "outputs": [],
      "source": [
        "# SMOTE\n",
        "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train==1)))\n",
        "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train==0)))\n",
        "\n",
        "X_res, y_res = SMOTE().fit_resample(X_train,y_train)\n",
        "\n",
        "print('After OverSampling, the shape of train_X: {}'.format(X_res.shape))\n",
        "print('After OverSampling, the shape of train_y: {} \\n'.format(y_res.shape))\n",
        "\n",
        "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_res==1)))\n",
        "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_res==0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a22f8c9e",
      "metadata": {
        "id": "a22f8c9e"
      },
      "outputs": [],
      "source": [
        "# Get new data generated by smote\n",
        "X_resampled = X_res[(X_train.shape[0]):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c64d9c55",
      "metadata": {
        "id": "c64d9c55"
      },
      "outputs": [],
      "source": [
        "# Get new data with label value 1.0\n",
        "X_real = X_train[y_train == 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a139b44c",
      "metadata": {
        "id": "a139b44c"
      },
      "outputs": [],
      "source": [
        "# hyperparameter\n",
        "n_epochs = 4000\n",
        "batch_size = 128\n",
        "latent_dim = X_train.shape[1] # 513"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cd69fa5",
      "metadata": {
        "id": "7cd69fa5"
      },
      "outputs": [],
      "source": [
        "# GAN model\n",
        "# generator_block\n",
        "def get_generator_block(input_dim, output_dim):\n",
        "    return nn.Sequential(\n",
        "        nn.Linear(input_dim, output_dim),\n",
        "        nn.BatchNorm1d(output_dim),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "    )\n",
        "# generator\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, z_dim=latent_dim, data_dim=latent_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.gen = nn.Sequential(\n",
        "            get_generator_block(z_dim, 1024),\n",
        "            get_generator_block(1024, 2048),\n",
        "            get_generator_block(2048, 4096),\n",
        "            get_generator_block(4096, 2048),\n",
        "            get_generator_block(2048, 1024),\n",
        "            nn.Linear(1024, data_dim),\n",
        "        )\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                init.kaiming_uniform_(m.weight.data, nonlinearity='leaky_relu')\n",
        "                if m.bias is not None:\n",
        "                    init.zeros_(m.bias.data)\n",
        "\n",
        "    def forward(self, noise):\n",
        "        return self.gen(noise)\n",
        "\n",
        "# discriminator_block\n",
        "def get_discriminator_block(input_dim, output_dim):\n",
        "    return nn.Sequential(\n",
        "        nn.Linear(input_dim, output_dim),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "        nn.Dropout(0.5)\n",
        "    )\n",
        "# 2.discriminator\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, data_dim=latent_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.disc = nn.Sequential(\n",
        "            get_discriminator_block(data_dim, 512),\n",
        "            get_discriminator_block(512, 1024),\n",
        "            get_discriminator_block(1024, 512),\n",
        "            get_discriminator_block(512, 256),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "    def forward(self, data):\n",
        "        return self.disc(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6e0aac8",
      "metadata": {
        "id": "b6e0aac8"
      },
      "outputs": [],
      "source": [
        "# Loss function\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Initialize generator and discriminator\n",
        "generator = Generator()\n",
        "discriminator = Discriminator()\n",
        "\n",
        "# Optimizers\n",
        "g_optimizer = torch.optim.Adam(generator.parameters(), lr=0.00001)\n",
        "d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=0.00001)\n",
        "\n",
        "# All the training set data with a label value of 1 are input into the discriminator as real data\n",
        "indices = (y_train == 1)\n",
        "X_real = X_train[indices]\n",
        "y_real = y_train[indices]\n",
        "my_dataset = TensorDataset(torch.Tensor(X_real.values), torch.Tensor(y_real.values))\n",
        "# dataloader\n",
        "dataloader = DataLoader(my_dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33975626",
      "metadata": {
        "id": "33975626"
      },
      "outputs": [],
      "source": [
        "# Train\n",
        "gen_losses = []\n",
        "disc_losses = []\n",
        "for epoch in range(n_epochs):\n",
        "    for i, real_data in enumerate(dataloader):\n",
        "        real_data = real_data[0].float()\n",
        "\n",
        "        # ---------------------\n",
        "        #  First Train Discriminator\n",
        "        # ---------------------\n",
        "\n",
        "        d_optimizer.zero_grad()\n",
        "\n",
        "        # Measure discriminator's ability to classify real from generated samples\n",
        "        disc_real_pred = discriminator(real_data)\n",
        "        real_loss = criterion(disc_real_pred, torch.ones_like(disc_real_pred))\n",
        "\n",
        "        gen_datas = generator(torch.Tensor(X_resampled.values).float())\n",
        "        disc_fake_pred = discriminator(gen_datas.detach())\n",
        "        fake_loss = criterion(disc_fake_pred, torch.zeros_like(disc_fake_pred))\n",
        "\n",
        "        d_loss = (real_loss + fake_loss) / 2\n",
        "\n",
        "        d_loss.backward()\n",
        "        d_optimizer.step()\n",
        "\n",
        "        # -----------------\n",
        "        #  Train Generator\n",
        "        # -----------------\n",
        "\n",
        "        g_optimizer.zero_grad()\n",
        "        gen_datas = generator(torch.Tensor(X_resampled.values).float())\n",
        "        disc_fake_pred = discriminator(gen_datas)\n",
        "        g_loss = criterion(disc_fake_pred, torch.ones_like(disc_fake_pred))\n",
        "\n",
        "        g_loss.backward()\n",
        "        g_optimizer.step()\n",
        "\n",
        "        gen_losses.append(g_loss.item())\n",
        "        disc_losses.append(d_loss.item())\n",
        "\n",
        "        print(\n",
        "            \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
        "            % (epoch, n_epochs, i, len(dataloader), d_loss.item(), g_loss.item())\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "695c6f92",
      "metadata": {
        "id": "695c6f92"
      },
      "outputs": [],
      "source": [
        "# Convert lists to NumPy arrays\n",
        "gen_losses = np.array(gen_losses)\n",
        "disc_losses = np.array(disc_losses)\n",
        "\n",
        "# Plot loss curves\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.plot(range(len(gen_losses)), gen_losses, label='Generator loss')\n",
        "plt.plot(range(len(disc_losses)), disc_losses, label='Discriminator loss')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "382623ae",
      "metadata": {
        "id": "382623ae"
      },
      "source": [
        "# t-SNE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb51be49",
      "metadata": {
        "id": "cb51be49"
      },
      "outputs": [],
      "source": [
        "real_one = X_train[y_train == 1]\n",
        "\n",
        "# count the frequency of each value in y_train.\n",
        "value_counts = y_train.value_counts()\n",
        "# calculate how much fewer the number of minority classes is than that of majority classes.\n",
        "diff = value_counts[0] - value_counts[1]\n",
        "\n",
        "# generator datas\n",
        "smote_z = torch.tensor(X_resampled.values, dtype=torch.float32)\n",
        "generated_data_smotegan = generator(smote_z)\n",
        "generated_data_smotegan_df = pd.DataFrame(generated_data_smotegan.detach().numpy(), columns=X_real.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a39557c6",
      "metadata": {
        "id": "a39557c6"
      },
      "outputs": [],
      "source": [
        "# t-SNE\n",
        "# original data (label==1)\n",
        "tsne_real = real_one # num == 76\n",
        "\n",
        "# smote data (label==1)\n",
        "tsne_real_smotegan = generated_data_smotegan_df # num == 392\n",
        "\n",
        "# TSNE\n",
        "combined_data = pd.concat([tsne_real_smotegan, tsne_real], axis=0)\n",
        "labels = np.array([0] * len(tsne_real_smotegan) + [1] * len(tsne_real))\n",
        "tsne = TSNE(n_components=2, random_state=42)\n",
        "tsne_data = tsne.fit_transform(combined_data)\n",
        "\n",
        "# show\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(tsne_data[labels == 0, 0], tsne_data[labels == 0, 1], c='b', label='SMOTified-GAN data')\n",
        "plt.scatter(tsne_data[labels == 1, 0], tsne_data[labels == 1, 1], c='r', label='Real data')\n",
        "plt.legend()\n",
        "plt.xlabel('Dimension 1')\n",
        "plt.ylabel('Dimension 2')\n",
        "plt.title('TSNE comparing real data with SMOTified-GAN generated data')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de3ebe17",
      "metadata": {
        "id": "de3ebe17"
      },
      "outputs": [],
      "source": [
        "# PCA\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# merge two datas\n",
        "merged_data = np.concatenate((real_one, generated_data_smotegan_df), axis=0)\n",
        "\n",
        "# PCA\n",
        "pca = PCA(n_components=2)  # dim==2\n",
        "\n",
        "pca.fit(merged_data)\n",
        "reduced_data = pca.transform(merged_data)\n",
        "\n",
        "# show\n",
        "plt.scatter(reduced_data[real_one.shape[0]:, 0], reduced_data[real_one.shape[0]:, 1], label='SMOTified-GAN data')\n",
        "plt.scatter(reduced_data[:real_one.shape[0], 0], reduced_data[:real_one.shape[0], 1], label='Real data')\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26219c36",
      "metadata": {
        "id": "26219c36"
      },
      "source": [
        "# SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "925d0f78",
      "metadata": {
        "id": "925d0f78"
      },
      "outputs": [],
      "source": [
        "# add the generated data to the training set, X_train_smotegan, y_res\n",
        "X_train_smotegan = X_train.append(generated_data_smotegan_df, ignore_index=True)\n",
        "y_train_smotegan = y_res\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "# shuffle\n",
        "X_train_smotegan, y_train_smotegan = shuffle(X_train_smotegan, y_train_smotegan, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e575e4d",
      "metadata": {
        "id": "2e575e4d"
      },
      "outputs": [],
      "source": [
        "# SVM\n",
        "import torch\n",
        "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve, average_precision_score, accuracy_score\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "def train_and_evaluate_svm(X_train, y_train, X_test, y_test):\n",
        "    X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
        "    y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
        "\n",
        "    # SVM\n",
        "    svm_classifier = SVC(probability=True)\n",
        "\n",
        "    # train\n",
        "    svm_classifier.fit(X_train_tensor.numpy(), y_train_tensor.numpy())\n",
        "\n",
        "    X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
        "    y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n",
        "\n",
        "    # test\n",
        "    y_scores = svm_classifier.predict_proba(X_test_tensor.numpy())[:, 1]\n",
        "    y_pred = svm_classifier.predict(X_test_tensor.numpy())\n",
        "\n",
        "    # FPR and TPR for ROC curve\n",
        "    fpr, tpr, thresholds = roc_curve(y_test_tensor.numpy(), y_scores)\n",
        "\n",
        "    # AUC\n",
        "    auc = roc_auc_score(y_test_tensor.numpy(), y_scores)\n",
        "\n",
        "    return auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70837c2a",
      "metadata": {
        "id": "70837c2a"
      },
      "outputs": [],
      "source": [
        "# original data\n",
        "roc_results = []\n",
        "\n",
        "# Repeat the training and evaluation process 30 times.\n",
        "num_repeats = 30\n",
        "for _ in range(num_repeats):\n",
        "    auc = train_and_evaluate_svm(X_train, y_train, X_test, y_test)\n",
        "    roc_results.append(auc)  # Store the AUC value in the tuple\n",
        "\n",
        "# Calculate the average value of evaluation indicators\n",
        "mean_auc = np.mean([result for result in roc_results])  # Retrieve the AUC value from the tuple\n",
        "\n",
        "print(\"Mean AUC:\", mean_auc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4af4c3d",
      "metadata": {
        "id": "c4af4c3d"
      },
      "outputs": [],
      "source": [
        "# smote data\n",
        "roc_results_smotegan = []\n",
        "\n",
        "# Repeat the training and evaluation process 30 times.\n",
        "num_repeats = 30\n",
        "for _ in range(num_repeats):\n",
        "    auc = train_and_evaluate_svm(X_train_smotegan, y_train_smotegan, X_test, y_test)\n",
        "    roc_results_smotegan.append(auc)  # Store the AUC value in the tuple\n",
        "\n",
        "# Calculate the average value of evaluation indicators\n",
        "mean_auc_smotegan = np.mean([result for result in roc_results_smotegan])  # Retrieve the AUC value from the tuple\n",
        "\n",
        "print(\"Mean AUC:\", mean_auc_smotegan)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}